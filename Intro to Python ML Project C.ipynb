{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy import stats\n",
    "from scipy.stats import mode\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFilePath = \"housing_filled.csv\"\n",
    "dataFile = pd.read_csv(dataFilePath)\n",
    "data = pd.DataFrame(dataFile)\n",
    "enc = LabelEncoder()\n",
    "dataDropped = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logit_y = dataDropped['OverallQual'] > 5\n",
    "logit_y = logit_y.map({True:1, False:0})\n",
    "\n",
    "#corr = dataDropped.corr()\n",
    "#print(corr['OverallQual'])\n",
    "\n",
    "logitdata = pd.DataFrame(dataDropped['SalePrice'] > 140000)\n",
    "logitdata['GarageCars'] = dataDropped['GarageCars']\n",
    "logitdata['GrLivArea'] = dataDropped['GrLivArea']\n",
    "logitdata['FullBath'] = dataDropped['FullBath']\n",
    "logitdata['1stFlrSF'] = dataDropped['1stFlrSF']\n",
    "logitdata['TotalBsmtSF'] = dataDropped['TotalBsmtSF']\n",
    "logitdata['1stFlrSF'] = dataDropped['1stFlrSF']\n",
    "logitdata['GarageYrBlt'] = dataDropped['GarageYrBlt']\n",
    "logitdata['YearRemodAdd'] = ((dataDropped['YearRemodAdd'] - 1900)/10).astype(int)\n",
    "logitdata['GarageArea'] = dataDropped['GarageArea']\n",
    "logitdata['GarageFinish'] = enc.fit_transform(dataDropped['GarageFinish'])\n",
    "logitdata['CBlock'] = dataDropped['Foundation'] == 'CBlock'\n",
    "logitdata['GoodExQual'] = (dataDropped['ExterQual'] == 'Ex') | (dataDropped['ExterQual'] == 'Gd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state: 4444\n",
      "improvement: 0.433734939759\n",
      "\n",
      "\n",
      "\n",
      "random_state: 912\n",
      "improvement: 0.435483870968\n",
      "\n",
      "\n",
      "\n",
      "random_state: 5702\n",
      "improvement: 0.429166666667\n",
      "\n",
      "\n",
      "\n",
      "random_state: 3502\n",
      "improvement: 0.424\n",
      "\n",
      "\n",
      "\n",
      "random_state: 1959\n",
      "improvement: 0.423387096774\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_sum = 0\n",
    "for rand_state in [4444,912,5702,3502,1959]:\n",
    "    logit_X_train, logit_X_test, logit_y_train, logit_y_test = train_test_split(logitdata, logit_y, test_size=0.3, random_state = rand_state)\n",
    "\n",
    "    # baseline\n",
    "    logit_baseline = np.full([len(logit_y_test),1],bool(logit_y_test.mode))\n",
    "\n",
    "    # model\n",
    "    logit = LogisticRegression()#class_weight = {'SalePrice': 0.5, 'YearBuilt':0.5}\n",
    "    logit.fit(logit_X_train, logit_y_train)\n",
    "    logit_pred = logit.predict(logit_X_test)\n",
    "\n",
    "    # accuracy\n",
    "    logit_baseline_score = accuracy_score(y_true = logit_y_test, y_pred = logit_baseline)\n",
    "    logit_model_score = accuracy_score(y_true = logit_y_test, y_pred = logit_pred)\n",
    "    logit_improvement = (logit_model_score - logit_baseline_score) / logit_baseline_score\n",
    "    print('random_state: ' + str(rand_state))\n",
    "    print('improvement: ' + str(logit_improvement))\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We first found the correlation between OverallQual and each feature and tried forming a model using the features with the greatest correlation with OverallQual. We then tried several features that were listed as categorical data. In particular, we focused on features with the word \"finish\" or \"quality\" in their descriptions. We did not need to change the threshold, as the threshold with the best results was generally around 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_y = dataDropped['Neighborhood']\n",
    "#treedata = dataDropped.drop(['Neighborhood'],axis=1)\n",
    "treedata = pd.DataFrame(dataDropped['HouseStyle'])\n",
    "treedata['BldgType'] = dataDropped['BldgType']\n",
    "treedata['LandSlope'] = dataDropped['LandSlope']\n",
    "treedata['Street'] = dataDropped['Street']\n",
    "treedata['YearBuilt'] = dataDropped['YearBuilt']\n",
    "treedata['Fence'] = dataDropped['Fence']\n",
    "treedata['SalePrice'] = dataDropped['SalePrice']\n",
    "\n",
    "for i in treedata.columns:\n",
    "    treedata[i] = enc.fit_transform(treedata[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_sum = 0\n",
    "for i in range(1,500):\n",
    "    tree_X_train, tree_X_test, tree_y_train, tree_y_test = train_test_split(treedata, tree_y, test_size=0.8)\n",
    "    \n",
    "    #baseline\n",
    "    neighborhood_frequencies = (tree_y_train.value_counts)(0)\n",
    "    neighborhood_frequencies = neighborhood_frequencies.index\n",
    "    neighborhood_mode = neighborhood_frequencies[0]\n",
    "    tree_baseline = np.ndarray([len(tree_y_test),1],dtype=object)\n",
    "    tree_baseline.fill(neighborhood_mode)\n",
    "    \n",
    "    #model\n",
    "    tree_classifier = DecisionTreeClassifier(max_leaf_nodes=15)\n",
    "    tree_classifier.fit(tree_X_train, tree_y_train)\n",
    "    with open(\"decisiontree.txt\", 'w') as f:\n",
    "        export_graphviz(tree_classifier, out_file=f, feature_names=list(treedata))\n",
    "    tree_pred = tree_classifier.predict(tree_X_test)\n",
    "\n",
    "    # measure accuracy\n",
    "    tree_baseline_score = accuracy_score(y_true = tree_y_test, y_pred = tree_baseline)\n",
    "    tree_model_score = accuracy_score(y_true = tree_y_test, y_pred = tree_pred)\n",
    "    tree_improvement = (tree_model_score - tree_baseline_score) / tree_baseline_score\n",
    "    tree_sum += tree_improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.58203046675\n"
     ]
    }
   ],
   "source": [
    "print(tree_sum / 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We first tried features that are directly related to geography, such as LandSlope and Street. We then tried features that might be trends in some neighborhoods, such as Fence. Lastly, we tried features that might be determined by construction -- that is, we used the fact that neighborhoods are often constructed all at once, with some uniformity in house type -- such as HouseStyle, BldgType, YearBuilt, and SalePrice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy import stats\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFilePath = \"housing_filled.csv\"\n",
    "dataFile = pd.read_csv(dataFilePath)\n",
    "data = pd.DataFrame(dataFile)\n",
    "enc = LabelEncoder()\n",
    "dataDropped = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_svm = pd.DataFrame(data['LotArea'])\n",
    "X_svm['OverallQual'] = data['OverallQual']\n",
    "X_svm['YearRemodAdd'] = data['YearRemodAdd']\n",
    "X_svm['1stFlrSF'] = data['1stFlrSF']\n",
    "X_svm['2ndFlrSF'] = data['2ndFlrSF']\n",
    "X_svm['LowQualFinSF'] = data['LowQualFinSF']\n",
    "X_svm['BsmtUnfSF'] = data['BsmtUnfSF']\n",
    "\n",
    "y_svm = data['HouseStyle']\n",
    "\n",
    "X_svm_train, X_svm_test, y_svm_train, y_svm_test = train_test_split(X_svm, y_svm, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline\n",
    "\n",
    "houseStyle_frequencies = (y_svm_train.value_counts)(0)\n",
    "houseStyle_frequencies = houseStyle_frequencies.index\n",
    "houseStyle_mode = houseStyle_frequencies[0]\n",
    "svm_baseline = np.ndarray([len(y_svm_test),1],dtype=object)\n",
    "svm_baseline.fill(houseStyle_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=100, gamma=0.0000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=1e-10, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_svm_train, y_svm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svm.predict(X_svm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     1.5Fin       0.50      0.02      0.04        54\n",
      "     1.5Unf       0.00      0.00      0.00         5\n",
      "     1Story       0.86      1.00      0.92       221\n",
      "     2.5Fin       0.00      0.00      0.00         2\n",
      "     2.5Unf       0.00      0.00      0.00         2\n",
      "     2Story       0.71      1.00      0.83       129\n",
      "     SFoyer       0.00      0.00      0.00         8\n",
      "       SLvl       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.71      0.80      0.72       438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#print(confusion_matrix(y_svm_test, predictions))\n",
    "\n",
    "print(classification_report(y_svm_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79908675799086759"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "svm.score(X_svm_test,y_svm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "We constrained our features to numerical ones. We focused on features that related to the size or quality of the house, since the size would relate to the number of stories in the house and the quality of the house would potentially relate to whether the house was finished. Then after decinding on features, we shifted the parameters, in particular the gamma parameter, until we obtained more than 75% baseline accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
